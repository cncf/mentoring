## Project Ideas

If you are a project maintainer and are considering mentoring during the GSoC 2026 cycle, please, submit your ideas below using the template.

[Google Summer of Code 2026 Announcement](https://groups.google.com/g/google-summer-of-code-discuss/c/D-aU3nHnGBQ/m/VU7lwF_MBQAJ)  
[Google Summer of Code Timeline](https://developers.google.com/open-source/gsoc/timeline)

Key GSoC 2026 dates:
* Organizations application period: Monday, Jan 19, to Tuesday, Feb 3, 2026
* CNCF Project proposals submissions recommendation: Wednesday Jan 14, 2026
  **Note**, proposals can still be submitted after this recommended date, but the Mentorship team needs time to evaluate the proposals and package our application. The more proposals we have, the stronger our org application will be.

You can find the project ideas from previous year [here](./2025.md).

> **NOTE:** Please note that GSoC is a program known for its strict deadlines. In addition to responding to your mentee on time, you will be required to submit evaluations on time. Failures to meet the deadlines might affect CNCF's future participation in GSoC.

---

### Template

```
#### CNCF Project Name

##### Project Title

- Description:
- Expected Outcome:
- Recommended Skills:
- Expected project size: # one of small (~90 hour projects), medium (~175 hour projects) and large (~350 hour projects)
- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.
  - Jane Doe (@jane-github, jane@email.address) - primary
  - John Doe (@john-github, john@email.address)
- Upstream Issue (URL):
```

---

## Ideas

#### Jaeger

##### AI-Powered Trace Analysis: Phase 2 - Self-Service "Skills" Framework

- **Description:** Jaeger is the industry-standard platform for distributed tracing. As microservice architectures grow complex, finding root causes in massive trace data becomes increasingly difficult. While Phase 1 of this initiative established a baseline AI assistant for natural language search, the system currently relies on hard-coded capabilities. This project (Phase 2\) aims to transform the Jaeger AI agent from a static chatbot into an extensible, user-programmable platform. The primary objective is to implement a "Self-Service Skills" framework, architecturally similar to "Claude Code Skills." This will allow end-users to teach the Jaeger AI new debugging workflows (e.g., "Analyze Critical Path" or "Detect N+1 Queries") by simply adding configuration files containing system prompts and logic rules, without needing to recompile the Jaeger binary. The applicant will build this extension within the Jaeger v2 (OpenTelemetry-based) architecture, utilizing **LangChainGo** to orchestrate interactions with Language Models (SLMs/LLMs). This project bridges the gap between generic AI reasoning and domain-specific observability expertise.
- **Expected Outcome:**
  - **Skills Engine Implementation:** A robust backend framework in Go that dynamically discovers, validates, and loads user-defined "Skills" (prompts and tool definitions) from configuration.
  - **Smart Analysis Features:** A polished implementation of Natural Language Search and Contextual Trace Explanation that intelligently leverages these loaded skills.
  - **Local-First Support:** Verified compatibility with local model runners (e.g., Ollama, Llama.cpp) to ensure deterministic performance without sending data to public clouds.
  - **UI Integration:** Enhancements to the Jaeger React UI to expose these AI capabilities and visualize the "reasoning steps" taken by the agent.
  - **Documentation:** A complete guide for users on "How to Author Custom AI Skills for Jaeger."
- **Learning Opportunities:**
  - **Agentic AI Architecture:** Learn to design stateful AI agents in Go that utilize "Tool Calling" and "Reasoning Loops" rather than simple text generation.
  - **OpenTelemetry Internals:** Gain deep familiarity with the OpenTelemetry Collector architecture, as Jaeger v2 is built directly on top of it.
  - **Cloud-Native Engineering:** Experience contributing to a graduated CNCF project, including navigating code reviews, writing design docs (RFDs), and adhering to open-source best practices.
  - **Full-Stack Development:** Practical experience bridging a complex Go backend with a modern React frontend.
- **Recommended Skills:**
  - **Languages:** Strong proficiency in **Go (Golang)** is required. Experience with **TypeScript/React** is highly recommended.
  - **AI/LLM:** Familiarity with LLM concepts (Prompt Engineering, RAG, Function Calling) and frameworks like LangChain.
  - **Domain Knowledge:** Basic understanding of distributed systems, observability, or debugging workflows is beneficial.
- **Expected project size:** Large (~350 hour projects)
- **Mentors:**
  - Jonah Kowall (@jkowall, jkowall@kowall.net)
  - Yuri Shkuro (@yurishkuro, github@ysh.us)
- Upstream Issue: https://github.com/jaegertracing/jaeger/issues/7827

### kgateway

##### Benchmarking and Performance Evaluation of Inference Routing Extensions in kgateway

- Description:
kgateway provides inference routing capabilities based on the Kubernetes Gateway API Inference Extension project. This integration enables advanced behaviors such as model-aware routing, serving priority, and customizable load-balancing of self-hosted Generative AI models.

However, there is currently no standardized or reproducible way to evaluate the performance impact of these inference routing extensions.

This project aims to design and implement a comprehensive benchmarking framework to measure the latency, throughput, and resource overhead introduced by inference routing extensions in kgateway. The benchmarks will help maintainers and users understand performance tradeoffs, validate optimizations, and guide future architectural decisions.

- Expected Outcome:
  - A reproducible benchmarking framework for inference routing extensions in kgateway
  - Benchmark scenarios covering:
    - Baseline gateway routing vs inference-enabled routing
    - Different inference extensions and EPP configurations
    - Request/response and streaming inference workloads
  - Collected metrics including:
    - End-to-end latency (p50 / p95 / p99)
    - Throughput
    - CPU and memory overhead
  - Automated benchmark execution (e.g., via CI or documented scripts)
  - Documentation describing benchmark methodology, results interpretation, and best practices

- Recommended Skills:
  - Go
  - Kubernetes
  - Familiarity with gateways or networking concepts
  - Basic understanding of AI inference workloads is a plus

- Expected project size:
  Medium (~175 hour projects)

- Mentor(s):
  - Primary Mentor: Nina Polshakova (@npolshakova, nina.polshakova@solo.io)
  - Secondary Mentor: Daneyon Hansen (@danehans, daneyon.hansen@solo.io)

- Upstream Issue (URL):
  https://github.com/kgateway-dev/kgateway/issues/12289

#### WasmEdge

##### Implement Custom Section Parsing and Branch Hinting proposal

- Description: As discussed in the [WasmEdge January 2026 community meeting](https://youtu.be/MKOHVU1VBzg), some toolchains may want to apply the branch hinting proposal. However, WasmEdge is currently unable to implement it due to the lack of custom section parsing. In this program, we aim to incorporate custom section parsing and branch hinting into the WasmEdge toolchain.
- Expected Outcome:
  - A series of test cases that verify the behavior of the custom section parsing and branch hinting proposal
  - An implementation of these defined features
  - A document discussing the design decisions and how to use them
- Recommended Skills:
  - C++
  - WebAssembly
- Expected project size: large
- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.
  - YiYing He (@q82419, yiying@secondstate.io) - primary
  - Hung-Ying, Tai (@hydai, hydai@secondstate.io)
- Upstream Issue (URL): https://github.com/WasmEdge/WasmEdge/issues/4517

#### OSCAL Compass 

##### OSCAL documents signing

- Description: CNCF OSCAL Compass trestle provides means to author and validate OSCAL documents including catalogs, profiles, component definitions and such. There is currently no standardized way to sign same.
- Expected Outcome:
  - trestle code to sign and verify signing of OSCAL documents
  - clear error messages for failures
  - sufficient test case coverage
  - documentation
  - tutorial
- Recommended Skills:
  - Python
- Expected project size: medium-to-large
- Mentor(s): #For GSoC, it is **required** to have at least 2 mentors with 1 being a primary mentor.
  - Lou DeGenaro (@Lou DeGenaro, lou.degenaro@gmail.com) - primary
  - Chris Butler (@Chris Butler, chris.butler@redhat.com)
  - Vikas Agarwal (@Vikas Agarwal, avikas@in.ibm.com)
- Upstream Issue (URL): https://github.com/oscal-compass/compliance-trestle/issues/2037
